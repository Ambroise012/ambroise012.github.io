---
title: "Paper : Adversarial Robustness in LLMs: Evaluating Two-Step Fine-Tuning and Spurious Correlation Extraction Methods"
collection: publications
permalink: publications/project3a-report
excerpt: >
    Abstract
    Recently, Large Language Models (LLMs) have achieved remarkable progress in text clas-002
    sification. However, they remain prone to spurious correlations or shortcuts—unintended as
    sociations between training data and task labels—that can degrade generalization and ad
    versarial robustness. Most existing approaches identify a limited set of task-specific short
    cuts using human priors or data augmentation, which require extensive expertise and manual
    effort. In this study, we investigate a two-step fine-tuning approach to mitigate such spurious
    correlations and improve model reliability. Our method involves an initial fine-tuning phase
    on the full dataset, followed by a second fine tuning phase on a subset identified as spurious
    using an extraction technique among important scores or LID scores. We evaluate our
    approach on four classification datasets (MNLI, HANS, FEVER, and FEVER-Symmetric) and
    find that this informed fine-tuning strategy enhances robustness. Our methods following at-
    tention scores prove to be the effective in identifying spurious correlations. Notably, with a
    BERT-base model, we achieve an accuracy of
    73.6% on HANS, compared to 62.9% with standard fine-tuning

[Link to the github repository](https://github.com/Ambroise012/robustness_to_spurious_correlation) 
date: '2025-03-31'
venue:
paperurl: '../files/Paper_spurious_correlation.pdf'
citation:
---
